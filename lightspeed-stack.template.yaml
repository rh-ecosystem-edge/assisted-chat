name: assisted-chat
service:
  host: 0.0.0.0
  port: 8090
  auth_enabled: false
  workers: 1
  color_log: true
  access_log: true
llama_stack:
  use_as_library_client: true
  library_client_config_path: "llama_stack_client_config.yaml"
mcp_servers:
  - name: mcp::assisted
    url: "http://assisted-service-mcp:8000/sse"
  - name: mcp::ocm
    url: "http://ocm-mcp:8000/sse"
user_data_collection:
  feedback_disabled: false
  feedback_storage: "/tmp/data/feedback"
  transcripts_disabled: false
  transcripts_storage: "/tmp/data/transcripts"
authentication:
  module: jwk-token
  jwk_config:
    url: https://sso.redhat.com/auth/realms/redhat-external/protocol/openid-connect/certs
    jwt_configuration:
      user_id_claim: sub
      username_claim: preferred_username
customization:
  system_prompt_path: "/tmp/systemprompt.txt"
  disable_query_system_prompt: false
inference:
  default_model: gemini/gemini/gemini-2.0-flash
  default_provider: gemini
