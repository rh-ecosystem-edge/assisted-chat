# vim: set filetype=dockerfile
FROM localhost/local-ai-chat-lightspeed-stack:latest

USER root

ADD ./llama-stack /app-root/llama-stack

RUN python3.12 -m ensurepip

RUN cd /app-root/llama-stack && python3.12 -m pip install --editable .

RUN cd /app-root/ && python3.12 -m pip install .

RUN python3.12 -m pip install pyyaml pyaml

RUN python3.12 -m pip install litellm

RUN python3.12 -m pip install sqlalchemy

RUN python3.12 -m pip install mcp

RUN python3.12 -m pip install faiss-cpu sentence_transformers

# Patch llama-stack with an important fix
RUN microdnf install -y patch
RUN cd /app-root/llama-stack && \
    curl -L https://github.com/meta-llama/llama-stack/commit/5e18d4d097d683056174b3c8b270806326e7ee96.patch | patch -p1

EXPOSE 8080
