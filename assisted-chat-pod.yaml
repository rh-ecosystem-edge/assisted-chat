apiVersion: v1
kind: Pod
metadata:
  name: assisted-chat-pod
spec:
  containers:
    - name: lightspeed-stack
      image: ${LIGHTSPEED_STACK_IMAGE_OVERRIDE}
      env:
        - name: GEMINI_API_KEY
          value: ${GEMINI_API_KEY}
      ports:
        - containerPort: 8090
          hostPort: 8090
      volumeMounts:
        - mountPath: /app-root/lightspeed-stack.yaml:Z
          name: config
          subPath: lightspeed-stack.yaml
        - mountPath: /app-root/llama_stack_client_config.yaml:Z
          name: config
          subPath: llama_stack_client_config.yaml
        - mountPath: /tmp/systemprompt.txt:Z
          name: config
          subPath: systemprompt.txt
        - mountPath: /app-root/llama_stack_vector_db:Z
          name: llama_stack_vector_db
        - mountPath: /app-root/embeddings_model:Z
          name: embeddings_model
    - name: assisted-service-mcp
      image: localhost/local-ai-chat-assisted-service-mcp:latest
    - name: ui
      image: localhost/local-ai-chat-ui
      env:
        - name: AIUI_CHATBOT_API_URL
          value: http://lightspeed-stack:8090
        - name: AIUI_APP_TOKEN
          value: ${OCM_TOKEN}
      ports:
        - containerPort: 8080
          hostPort: 8080
    - name: mcp-inspector
      image: localhost/local-ai-chat-inspector:latest
      ports:
        - containerPort: 6274
          hostPort: 6274
    - name: mcphost
      image: quay.io/otuchfel/mcphost:0.9.2 
      tty: true
      stdin: true
      args:
        - --config
        - /mcpconfig.json
        - --model
        - "google:gemini-2.0-flash"
        - --system-prompt
        - /systemprompt.txt
      env:
        - name: GEMINI_API_KEY
          value: ${GEMINI_API_KEY}
        - name: OCM_TOKEN
          value: ${OCM_TOKEN}
      volumeMounts:
        - mountPath: /mcpconfig.json
          name: config
          subPath: mcphost-mcp.json
        - mountPath: /systemprompt.txt
          name: config
          subPath: systemprompt.txt
  volumes:
    - name: config
      hostPath:
        path: ./config
        type: Directory
    - name: llama_stack_vector_db
      hostPath:
        path: ./llama_stack_vector_db
        type: Directory
    - name: embeddings_model
      hostPath:
        path: ./embeddings_model
        type: Directory
